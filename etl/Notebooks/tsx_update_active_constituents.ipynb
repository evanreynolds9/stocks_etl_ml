{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T16:36:55.560965Z",
     "start_time": "2025-12-07T16:36:48.390812Z"
    }
   },
   "source": [
    "# Install packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from sqlalchemy import text, create_engine, MetaData, Table, update, and_, Update, insert\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "# Import utils\n",
    "from etl.utils.utils import extract_query, load_query"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:36:58.863124Z",
     "start_time": "2025-12-07T16:36:57.859766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create db connection string\n",
    "db_username = os.getenv(\"DB_USERNAME\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_conn_str = f\"mysql+pymysql://{db_username}:{db_password}@{db_host}:{db_port}/tsx_composite_index\"\n",
    "\n",
    "# Set name for table in database\n",
    "staging_table = \"ticker_staging_table\"\n",
    "company_table = \"company\"\n",
    "ticker_table = \"ticker_history\"\n",
    "\n",
    "# Create database engine\n",
    "db_engine = create_engine(db_conn_str)\n",
    "\n",
    "# Load metadata container\n",
    "metadata = MetaData()"
   ],
   "id": "b17e7c6c7c924b01",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:37:00.677069Z",
     "start_time": "2025-12-07T16:37:00.512508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pull data from staging table\n",
    "staging_df = extract_query(table_name=staging_table, engine=db_engine)"
   ],
   "id": "3060485fb1b06fc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Successful!\n",
      "ticker_staging_table loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:37:03.856841Z",
     "start_time": "2025-12-07T16:37:03.831782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pull data from current ticker table\n",
    "cur_tickers_query = text(\"\"\"\n",
    "SELECT company_id, tsx_ticker, company_name\n",
    "FROM ticker_history\n",
    "WHERE end_date IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "tickers_df = extract_query(sql_query=cur_tickers_query, engine=db_engine)"
   ],
   "id": "6f1c695e18e27739",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Successful!\n",
      "SQL script executed successfully!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:37:06.987116Z",
     "start_time": "2025-12-07T16:37:06.976925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get date_created from staging table\n",
    "date_created = staging_df['date_created'][0]"
   ],
   "id": "f688a79cda377047",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:37:14.830817Z",
     "start_time": "2025-12-07T16:37:14.786295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Outer join the two dataframes\n",
    "full_df = tickers_df.merge(staging_df, how = \"outer\", left_on = [\"tsx_ticker\", \"company_name\"], right_on = [\"company_s\", \"company_n\"])"
   ],
   "id": "85d066bcf1f13547",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:41:33.572715Z",
     "start_time": "2025-12-07T16:41:33.485485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If there are no nulls, we have matched an existing row, and edits are needed\n",
    "# If there are nulls, segment into the nulls from tsx_ticker and company_name vs company_s and company_n. We then have several cases:\n",
    "### For the nulls in tsx_ticker and comp_name, check if the company has had a name/ticker change:\n",
    "###### If yes: match to the corresponding row with null company_s/company_n. Then, set end_date = date_created, end_reason = 'C' for those company_ids on db table.\n",
    "###### Finally, insert new rows with company_id, company_s, company_n, yfinance_ticker (computed) and record_created\n",
    "###### If no: for leftover rows with null in company_s/company_n, set end_date = date_created, end_reason = 'R' for those company_ids on db table.\n",
    "###### For rows left with null in tsx_ticker/company_name, first insert a new row into the company table with company_name.\n",
    "###### Then pull rows from that table with name in company_n and date_created = date_created, and insert them into the ticker table with\n",
    "###### company_id, company_s, company_n, yfinance_ticker (computed) and record_created\n",
    "df_left = full_df[full_df[\"company_n\"].isna() & full_df[\"company_s\"].isna()][[\"company_id\", \"tsx_ticker\", \"company_name\"]]\n",
    "df_right = full_df[full_df[\"company_id\"].isna() & full_df[\"tsx_ticker\"].isna()][[\"company_s\", \"company_n\", \"date_created\"]]\n",
    "df_matches = pd.DataFrame()"
   ],
   "id": "2f94cec669298d66",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:41:44.174124Z",
     "start_time": "2025-12-07T16:41:44.136298Z"
    }
   },
   "cell_type": "code",
   "source": "df_right",
   "id": "c64b6f4f2bb86192",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    company_s                                     company_n date_created\n",
       "0         AAV                         Advantage Energy Ltd.   2025-11-30\n",
       "1         ABX                    Barrick Mining Corporation   2025-11-30\n",
       "2          AC  Air Canada Voting and Variable Voting Shares   2025-11-30\n",
       "3       ACO.X           ATCO Ltd. Class I Non-voting Shares   2025-11-30\n",
       "4         AEM                    Agnico Eagle Mines Limited   2025-11-30\n",
       "..        ...                                           ...          ...\n",
       "206        WN                         George Weston Limited   2025-11-30\n",
       "207       WPK                                   Winpak Ltd.   2025-11-30\n",
       "208       WPM                 Wheaton Precious Metals Corp.   2025-11-30\n",
       "209       WSP                               WSP Global Inc.   2025-11-30\n",
       "210         X                             TMX Group Limited   2025-11-30\n",
       "\n",
       "[211 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_s</th>\n",
       "      <th>company_n</th>\n",
       "      <th>date_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAV</td>\n",
       "      <td>Advantage Energy Ltd.</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABX</td>\n",
       "      <td>Barrick Mining Corporation</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AC</td>\n",
       "      <td>Air Canada Voting and Variable Voting Shares</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACO.X</td>\n",
       "      <td>ATCO Ltd. Class I Non-voting Shares</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM</td>\n",
       "      <td>Agnico Eagle Mines Limited</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>WN</td>\n",
       "      <td>George Weston Limited</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>WPK</td>\n",
       "      <td>Winpak Ltd.</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>WPM</td>\n",
       "      <td>Wheaton Precious Metals Corp.</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>WSP</td>\n",
       "      <td>WSP Global Inc.</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>X</td>\n",
       "      <td>TMX Group Limited</td>\n",
       "      <td>2025-11-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:41:51.378355Z",
     "start_time": "2025-12-07T16:41:51.323261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start matches UI if there are rows in both dfs, and let user match rows if necessary\n",
    "if len(df_left) > 0 and len(df_right) > 0:\n",
    "    def match_rows():\n",
    "        global df_left, df_right, df_matches\n",
    "\n",
    "        left_idx = left_listbox.curselection()\n",
    "        right_idx = right_listbox.curselection()\n",
    "        if not left_idx or not right_idx:\n",
    "            return  # require a selection on both sides\n",
    "\n",
    "        # Extract full rows\n",
    "        left_row = df_left.iloc[left_idx[0]]\n",
    "        right_row = df_right.iloc[right_idx[0]]\n",
    "\n",
    "        # Combine into one row\n",
    "        combined = pd.concat([left_row, right_row])\n",
    "\n",
    "        # Append to matches DataFrame\n",
    "        df_matches = pd.concat([df_matches, combined.to_frame().T], ignore_index=True)\n",
    "\n",
    "        # Show match in Matches window\n",
    "        match_listbox.insert(\n",
    "            tk.END,\n",
    "            f\"{left_row['tsx_ticker']} - {left_row['company_name']} ↔ {right_row['company_s']} - {right_row['company_n']}\"\n",
    "        )\n",
    "\n",
    "        # Drop matched rows from original DataFrames\n",
    "        df_left = df_left.drop(left_row.name).reset_index(drop=True)\n",
    "        df_right = df_right.drop(right_row.name).reset_index(drop=True)\n",
    "\n",
    "        # Remove matched rows from listboxes\n",
    "        left_listbox.delete(left_idx[0])\n",
    "        right_listbox.delete(right_idx[0])\n",
    "\n",
    "        # Clear selections\n",
    "        left_listbox.selection_clear(0, tk.END)\n",
    "        right_listbox.selection_clear(0, tk.END)\n",
    "\n",
    "    def finish_process():\n",
    "        # Print matches\n",
    "        print(\"The following rows were matched:\")\n",
    "        print(df_matches)\n",
    "\n",
    "        root.destroy()  # close the GUI cleanly\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Row Matcher: Match rows if necessary\")\n",
    "\n",
    "    # Left Listbox\n",
    "    left_listbox = tk.Listbox(root, selectmode=\"browse\", exportselection=False)\n",
    "    for _, row in df_left.iterrows():\n",
    "        left_listbox.insert(tk.END, f\"{row['tsx_ticker']} - {row['company_name']}\")\n",
    "    left_listbox.pack(side=\"left\", padx=10, pady=10, fill=\"y\")\n",
    "\n",
    "    # Right Listbox\n",
    "    right_listbox = tk.Listbox(root, selectmode=\"browse\", exportselection=False)\n",
    "    for _, row in df_right.iterrows():\n",
    "        right_listbox.insert(tk.END, f\"{row['company_s']} - {row['company_n']}\")\n",
    "    right_listbox.pack(side=\"right\", padx=10, pady=10, fill=\"y\")\n",
    "\n",
    "    # Match button\n",
    "    btn = tk.Button(root, text=\"Match\", command=match_rows)\n",
    "    btn.pack(pady=10)\n",
    "\n",
    "    # Finished button\n",
    "    finish_btn = tk.Button(root, text=\"Finished\", command=finish_process, bg=\"lightgreen\")\n",
    "    finish_btn.pack(pady=10)\n",
    "\n",
    "    # Matches window\n",
    "    matches_win = tk.Toplevel(root)\n",
    "    matches_win.title(\"Matches\")\n",
    "    match_listbox = tk.Listbox(matches_win, width=60, exportselection=False)\n",
    "    match_listbox.pack(padx=10, pady=10, fill=\"both\")\n",
    "\n",
    "    root.mainloop()"
   ],
   "id": "535f67d31270e7eb",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:41:55.762030Z",
     "start_time": "2025-12-07T16:41:55.743892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define function to construct a statement to invalidate rows based on matching columns\n",
    "def invalidate_rows(table: Table, row: pd.Series, date_created: str, end_reason: str) -> Update:\n",
    "    # Define statement\n",
    "    stmt = (\n",
    "            update(table)\n",
    "            .where(\n",
    "                and_(\n",
    "                    table.c.company_id == row[\"company_id\"],\n",
    "                    table.c.tsx_ticker == row[\"tsx_ticker\"],\n",
    "                    table.c.company_name == row[\"company_name\"],\n",
    "                    table.c.end_date.is_(None)\n",
    "                )\n",
    "            )\n",
    "            .values(\n",
    "                end_date = date_created,\n",
    "                end_reason = end_reason\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return stmt"
   ],
   "id": "54d941540386ee00",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:42:16.552043Z",
     "start_time": "2025-12-07T16:42:16.247113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set end_date for remaining rows in left table and matched rows\n",
    "ticker_table_db = Table(ticker_table, metadata, autoload_with=db_engine)\n",
    "\n",
    "# Begin engine session\n",
    "with db_engine.begin() as conn:\n",
    "    # First, invalidate the rows for the current name/tickers in the matched table\n",
    "    for _, row in df_matches.iterrows():\n",
    "        # Create statement to invalidate rows\n",
    "        stmt = invalidate_rows(table=ticker_table_db, row=row, date_created=date_created, end_reason=\"C\")\n",
    "\n",
    "        # Execute transaction\n",
    "        conn.execute(stmt)\n",
    "\n",
    "    # Next, Invalidate each row in df_left\n",
    "    for _, row in df_left.iterrows():\n",
    "        # Create statement to invalidate rows\n",
    "        stmt = invalidate_rows(table=ticker_table_db, row=row, date_created=date_created, end_reason=\"R\")\n",
    "\n",
    "        # Execute transaction\n",
    "        conn.execute(stmt)"
   ],
   "id": "84cb361bff01d1f8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:43:33.401707Z",
     "start_time": "2025-12-07T16:43:33.385892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Insert rows for matches (new tickers/names) into table, if any exist\n",
    "if len(df_matches) > 0:\n",
    "    # Drop columns\n",
    "    df_matches.drop(columns = [\"tsx_ticker\", \"company_name\"], inplace=True)\n",
    "\n",
    "    # Rename columns\n",
    "    df_matches.rename(columns = {\"company_s\": \"tsx_ticker\", \"company_n\": \"company_name\", \"date_created\": \"start_date\"}, inplace=True)\n",
    "\n",
    "    # Generate yfinance ticker\n",
    "    df_matches[\"yfinance_ticker\"] = df_matches[\"tsx_ticker\"].str.replace(\".\", \"-\") + \".TO\"\n",
    "\n",
    "    # Reorder columns\n",
    "    df_matches = df_matches[[\"company_id\", \"tsx_ticker\", \"company_name\", \"yfinance_ticker\", \"start_date\"]]\n",
    "\n",
    "    # Insert into database\n",
    "    load_query(table_name = ticker_table, df = df_matches, engine = db_engine)"
   ],
   "id": "29d58d7f2c227cac",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:43:52.117356Z",
     "start_time": "2025-12-07T16:43:50.951721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Insert rows for new companies into company table\n",
    "\n",
    "# First, define table using Table class\n",
    "company_table_db = Table(company_table, metadata, autoload_with=db_engine)\n",
    "\n",
    "# Create empty list for ids\n",
    "ids = []\n",
    "\n",
    "# Create session, and store ids\n",
    "with Session(db_engine) as session:\n",
    "    for _, row in df_right.iterrows():\n",
    "        stmt = insert(company_table_db).values({\"initial_name\":row[\"company_n\"], \"date_created\": row[\"date_created\"]})\n",
    "        result = session.execute(stmt)\n",
    "        session.commit()\n",
    "        ids.append(result.inserted_primary_key[0])\n",
    "\n",
    "# Add the ids to the dataframe\n",
    "df_right[\"company_id\"] = ids"
   ],
   "id": "778b396e42696d6d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:45:10.994179Z",
     "start_time": "2025-12-07T16:45:10.908459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finally, insert rows for new companies into ticker table\n",
    "\n",
    "# Rename columns\n",
    "df_right.rename(columns = {\"company_s\": \"tsx_ticker\", \"company_n\": \"company_name\", \"date_created\": \"start_date\"}, inplace=True)\n",
    "\n",
    "# Add column for yfinance_tickers\n",
    "df_right[\"yfinance_ticker\"] = df_right[\"tsx_ticker\"].str.replace(\".\", \"-\") + \".TO\"\n",
    "\n",
    "# Reorder columns\n",
    "df_right = df_right[[\"company_id\", \"tsx_ticker\", \"company_name\", \"yfinance_ticker\", \"start_date\"]]\n",
    "\n",
    "# Insert into db\n",
    "load_query(table_name = ticker_table, df = df_right, engine = db_engine)"
   ],
   "id": "93bb38fcd7dc52f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 rows uploaded successfully to ticker_history.\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
