{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:01.038830Z",
     "start_time": "2025-11-23T21:13:59.539418Z"
    }
   },
   "source": [
    "# Install selenium packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "# Install other packages\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# Import utils\n",
    "from etl_utils import load_query, extract_query"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:01.603153Z",
     "start_time": "2025-11-23T21:14:01.590126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load chrome driver path\n",
    "load_dotenv()\n",
    "chrome_driver_path = os.getenv(\"CHROME_DRIVER_PATH\")\n",
    "\n",
    "# Create db connection string\n",
    "db_username = os.getenv(\"DB_USERNAME\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_conn_str = f\"mysql+pymysql://{db_username}:{db_password}@{db_host}:{db_port}/stocks_etl_ml_db\"\n",
    "\n",
    "# Set url for page on tmx website\n",
    "tmx_link = \"https://money.tmx.com/en/quote/%5ETSX/constituents\"\n",
    "\n",
    "# Set name for table in database\n",
    "table_name = \"tsx_composite_constituents\""
   ],
   "id": "541e71e8f69a4043",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:03.297956Z",
     "start_time": "2025-11-23T21:14:03.285685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create dict for company names and symbols\n",
    "tsx_constituents = {'Company_Name': [],\n",
    "                    'Company_Symbol': []}"
   ],
   "id": "3f61dd9cd114a31f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:06.007007Z",
     "start_time": "2025-11-23T21:14:04.192968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure webdriver\n",
    "service = Service(executable_path=chrome_driver_path)\n",
    "driver = webdriver.Chrome(service=service)"
   ],
   "id": "b9e1765099dfbe80",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:20.129705Z",
     "start_time": "2025-11-23T21:14:12.218640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup page counter\n",
    "i = 1\n",
    "\n",
    "# Setup main function\n",
    "try:\n",
    "    driver.get(tmx_link)\n",
    "    # Create while loop\n",
    "    while True:\n",
    "        # Load list from page\n",
    "        tmx_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Get the constituent list table\n",
    "        constituent_table = tmx_soup.find('div','ConstituentsList__ConstituentsTable-sc-q9ist-1')\n",
    "\n",
    "        # Get the company names and tickers from this table\n",
    "        company_names = constituent_table.find_all('div', 'ConstituentsList__CompanyName-sc-q9ist-6')\n",
    "        company_symbols = constituent_table.find_all('span', 'ConstituentsList__SymbolLink-sc-q9ist-7')\n",
    "\n",
    "        # Extract names and symbols\n",
    "        for name_div, symbol_div in zip(company_names, company_symbols):\n",
    "            tsx_constituents['Company_Name'].append(name_div.text)\n",
    "            tsx_constituents['Company_Symbol'].append(symbol_div.text)\n",
    "\n",
    "        # Find the next page button\n",
    "        next_button = WebDriverWait(driver, 10).until(lambda x: x.find_element(By.CSS_SELECTOR, \"button[data-testid='paginator-next']\"))\n",
    "\n",
    "        # Check if it is disabled\n",
    "        is_disabled = next_button.get_attribute(\"disabled\")\n",
    "\n",
    "        if is_disabled is not None:\n",
    "            print(\"All symbols have been collected. Terminating data collection and closing driver session.\")\n",
    "            driver.quit()\n",
    "            break\n",
    "\n",
    "        # Click button with execute script to bypass sticky banner ads\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "        print(f\"Company data extracted from page {i}\")\n",
    "        i+=1\n",
    "\n",
    "# Catch any exception\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred on page {i}: {e}\")"
   ],
   "id": "55139d105dcedabe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company data extracted from page 1\n",
      "Company data extracted from page 2\n",
      "Company data extracted from page 3\n",
      "Company data extracted from page 4\n",
      "Company data extracted from page 5\n",
      "Company data extracted from page 6\n",
      "Company data extracted from page 7\n",
      "Company data extracted from page 8\n",
      "Company data extracted from page 9\n",
      "Company data extracted from page 10\n",
      "Company data extracted from page 11\n",
      "Company data extracted from page 12\n",
      "Company data extracted from page 13\n",
      "Company data extracted from page 14\n",
      "Company data extracted from page 15\n",
      "Company data extracted from page 16\n",
      "Company data extracted from page 17\n",
      "Company data extracted from page 18\n",
      "Company data extracted from page 19\n",
      "Company data extracted from page 20\n",
      "Company data extracted from page 21\n",
      "All symbols have been collected. Terminating data collection and closing driver session.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:20.161507Z",
     "start_time": "2025-11-23T21:14:20.145730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Put data into a dataframe\n",
    "df = pd.DataFrame(tsx_constituents)"
   ],
   "id": "a6bb1ba500aaf5bd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:21.073014Z",
     "start_time": "2025-11-23T21:14:21.051576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add columns for last seen, last_check, and whether symbol exists\n",
    "cur_date = pd.to_datetime(\"today\").normalize()\n",
    "df[\"Last_Seen\"] = cur_date\n",
    "df[\"Last_Check\"] = cur_date\n",
    "df[\"Current_Constituent\"] = True"
   ],
   "id": "f7fc5d38eecad890",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:22.984752Z",
     "start_time": "2025-11-23T21:14:22.879299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Connect to database and check if this table exists\n",
    "engine = sa.create_engine(db_conn_str)\n",
    "insp = sa.inspect(engine)"
   ],
   "id": "d4e516a263e7ffcf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:14:24.790515Z",
     "start_time": "2025-11-23T21:14:24.622952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if the table exists\n",
    "if not insp.has_table(table_name, schema = \"dbo\"):\n",
    "    # Load table to database\n",
    "    load_query(table_name = table_name, df = df, engine = engine)\n",
    "\n",
    "else: # We want to extract the table, and check which companies match\n",
    "    current_tsx_constituents = extract_query(table_name = table_name, engine = engine)\n",
    "\n",
    "    cols_to_drop = [\"Last_Check\", \"Current_Constituent\"]\n",
    "    # Perform an outer join\n",
    "    df_merged = pd.merge(current_tsx_constituents.drop(columns = [cols_to_drop]),\n",
    "                         df.drop(columns = [cols_to_drop]),\n",
    "                         on = [\"Company_Name\", \"Company_Symbol\"],\n",
    "                         how = \"outer\",\n",
    "                         suffixes = (\"_left\", \"_right\"))\n",
    "\n",
    "    # Keep last_seen, current_max from new table if there was a match\n",
    "    df_merged[\"Last_Seen\"] = df_merged[\"Last_Seen_right\"].combine_first(df_merged[\"Last_Seen_left\"])\n",
    "    df_merged[\"Last_Seen\"] = df_merged[\"Last_Seen_right\"].combine_first(df_merged[\"Last_Seen_left\"])\n",
    "\n",
    "    # Drop columns\n",
    "    df_merged.drop(columns = [\"Last_Seen_right\", \"Last_Seen_left\"], inplace = True)\n",
    "\n",
    "    # Set max_date\n",
    "    df_merged[\"Last_Check\"] = cur_date\n",
    "\n",
    "    # Set whether ticker is active\n",
    "    df_merged[\"Current_Constituent\"] = (df_merged[\"Last_Seen\"] == df_merged[\"Last_Check\"])\n",
    "\n",
    "    # Load query to database\n",
    "    load_query(table_name=table_name, df=df_merged, append=False, engine=engine)"
   ],
   "id": "96ca6b6b0a2a4c1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table columns align: continuing to data upload.\n",
      "211 rows uploaded successfully to tsx_composite_constituents.\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
